{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del Lenguaje Natural\n",
    "\n",
    "## Generación de un modelo de lenguaje utilizando redes neuronales\n",
    "\n",
    "Francisco Pablo Rodrigo\n",
    "\n",
    "El modelo del lenguaje neuronal propuesto por Bengio (2003) es un modelo que estima probabilidades a partir de una red neuronal FeedForward. Como otros modelos, se puede entender como una tupla:\n",
    "\n",
    "$$\\mu = (\\Sigma, P)$$\n",
    "\n",
    "donde $\\Sigma$ es el vocabulario de palabras y $P = p(w_j|w_i)$ es la probabilidad de transición de $w_i$ a $w_j$. En este caso $P$ es una red FeedForward con una arquitectura constituida por:\n",
    "\n",
    "* Una capa de embedding.\n",
    "* Una capa oculta con activación $\\tanh$.\n",
    "* Una capa de salida con activación Softmax para obtener las probabilidades de transición.\n",
    "\n",
    "\n",
    "### Configuraciones previas\n",
    "\n",
    "Se realizan los *imports* necesarios para la creación del modelo. Para el entrenamiento del modelo se puede hacer uso de PyTorch o Tensorflow o cualquier otra librería que tenga redes neuronales pre-entrenadas, sin embargo, para este ejercicio se creará la red desde cero utilizando simplemente _numpy_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- encoding:utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos tres funciones:\n",
    "\n",
    "* Función para crear el vocabulario: asocia índices numéricos a palabras\n",
    "* Función para asociar a cada elemento, una palabra\n",
    "* Función para visualizar los embeddings por reducción de dimensionalidad con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que crea un vocabulario de palabras con un indice numero\n",
    "def vocab():\n",
    "    vocab = defaultdict()\n",
    "    vocab.default_factory = lambda: len (vocab)\n",
    "    return vocab\n",
    "\n",
    "# Funcion que pasa la cadena de simbolos a una secuencia con indices numericos\n",
    "def text2numba(corpus, vocab):\n",
    "    for doc in corpus:\n",
    "        yield [vocab[w] for w in doc]\n",
    "        \n",
    "#Función para visualizar los embeddings\n",
    "#Usa reducción de la dimensionalidad por PCA\n",
    "def plot_words(Z,ids):\n",
    "    Z = PCA(2).fit_transform(Z)\n",
    "    r=0\n",
    "    plt.scatter(Z[:,0],Z[:,1], marker='o', c='blue')\n",
    "    for label,x,y in zip(ids, Z[:,0], Z[:,1]):\n",
    "        plt.annotate(label, xy=(x,y), xytext=(-1,1), textcoords='offset points', ha='center', va='bottom')\n",
    "        r+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elección de un corpus\n",
    "\n",
    "Un **corpus** es una muestra bien organizada del nuestro lenguaje tomada de materiales escritos o hablados y que se encuentran agrupados bajo un críterio común. Para esta práctica se utilizará un corpus en *español*.\n",
    "\n",
    "Obtenemos las sentencias con las que vamos a trabajar. Tokenizamos por oraciones y cada oración, a su vez, es tokenizada por palabras para obtener los elementos que servirán para el modelo del lenguaje.\n",
    "\n",
    "Posteriormente, separamos los datos del corpus en el corpus de entrenamiento y el de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de oraciones en train: 88\n",
      "Número de oraciones en test: 39\n"
     ]
    }
   ],
   "source": [
    "# OPCION 1\n",
    "sents =  [word_tokenize(s) for s in sent_tokenize(open('corpus/funes_el_memorioso.txt','r').read())]\n",
    "\n",
    "#Split en corpus train y test\n",
    "corpus, corpus_eval = train_test_split(sents, test_size=0.3)\n",
    "\n",
    "print('Número de oraciones en train:',len(corpus))\n",
    "print('Número de oraciones en test:',len(corpus_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCION 2\n",
    "#import nltk\n",
    "#nltk.download('gutenberg')\n",
    "#sents = cess_esp.sents()\n",
    "#nltk.download('punkt')\n",
    "#sents = nltk.corpus.gutenberg.sents('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ver el número de tipos y tokens con el que cuenta el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tipos: 856 \n",
      "Número de tokens: 2229\n"
     ]
    }
   ],
   "source": [
    "#Frecuencia de los tipos\n",
    "freq_words= Counter( chain(*[' '.join(sent).lower().split() for sent in corpus]) )\n",
    "\n",
    "print('Número de tipos: {} \\nNúmero de tokens: {}'.format(len(freq_words), sum(freq_words.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sustitución de los hapax\n",
    "\n",
    "Ahora sustituiremos elementos del texto por el símbolo de fuera del vocabulario (Out Of Vocabulary) o $OOV$ esto nos permitirá manejar elementos que no se observen durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuevo corpus remplazando hápax por OOV\n",
    "corpus_hapax = []\n",
    "#Reemplazamos los hápax por OOV\n",
    "for sent in corpus:\n",
    "  sent_hapax =[]\n",
    "  for w in sent:\n",
    "    #Si es hápax\n",
    "    if freq_words[w.lower()] == 1:\n",
    "      #Se reemplaza por <oov>\n",
    "      sent_hapax.append('<oov>')\n",
    "    else:\n",
    "      #De otra forma se mantiene la palabra en mínuscula\n",
    "      sent_hapax.append(w.lower())\n",
    "  #Se agrupan las cadenas    \n",
    "  corpus_hapax.append(sent_hapax)\n",
    "    \n",
    "#print(corpus_hapax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Stemming\n",
    "\n",
    "Para esta tarea no realizará el proceso de steamming con la finalidad de simplificar la validación del modelo, ya que de otra manera se deberían reconstruir las cadenas a la hora de evaluar el modelo o a la hora de usarlo para alguna aplicación, por ejemplo, la generación de oraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Insertar símbolos de inicio y final de cadena\n",
    "\n",
    "Se indexa númericamente cada simbolo del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la funcion para crear un vocabulario\n",
    "idx = vocab() # Simplemente se renombra la funcion\n",
    "\n",
    "cads_idx = list(text2numba(corpus_hapax,idx))\n",
    "\n",
    "#print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, se colocarán etiquetas al inicio y al final de cada sentencia: BOS (Beginning of Sentence) y EOS (End of Sentence) respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194, 0, 1, 2, 1, 3, 4, 5, 6, 1, 3, 7, 8, 9, 10, 1, 1, 2, 11, 12, 13, 14, 1, 3, 1, 9, 7, 1, 3, 15, 16, 1, 2, 17, 18, 19, 20, 7, 1, 9, 21, 1, 22, 1, 1, 3, 15, 1, 11, 1, 4, 7, 1, 1, 9, 17, 1, 22, 1, 3, 1, 9, 11, 1, 22, 1, 3, 15, 1, 23, 1, 9, 1, 24, 1, 25, 1, 26, 27, 28, 29, 193], [194, 24, 1, 30, 1, 31, 1, 9, 15, 1, 8, 1, 29, 193]]\n"
     ]
    }
   ],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "\n",
    "# A cada etiqueta se le asigna el indice número mayor \n",
    "# que el último indice asignado al vocabulario\n",
    "\n",
    "BOS_IDX = max(idx.values()) + 2\n",
    "EOS_IDX = max(idx.values()) + 1\n",
    "\n",
    "# Se agregan las etiquetas al vocabulario\n",
    "idx[EOS] = EOS_IDX\n",
    "idx[BOS] = BOS_IDX\n",
    "\n",
    "# Agregamos las etiquetas BOS al inicio y EOS al final de cada sentencia\n",
    "\n",
    "strings = [[BOS_IDX] + cad + [EOS_IDX] for cad in cads_idx]\n",
    "\n",
    "print(strings[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bigramas\n",
    "\n",
    "Antes de entrenar el modelo del lenguaje obtendremos los pares de entrenamiento que serán los pares obtenidos de bigramas, de tal forma que nuestro conjunto supervisado será:\n",
    "\n",
    "$$\\mathcal{S} = \\{(i,j) : (w_i, w_j) \\text{ es un bigrama}\\}$$\n",
    "Antes de obtener estos bigramas, además, debemos agregar los símbolos de $BOS$ y $EOS$, así como crear el vocabulario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317\n"
     ]
    }
   ],
   "source": [
    "# Creacion de bigramas\n",
    "bigrams = list(chain(*[zip(cad,cad[1:]) for cad in strings]))\n",
    "print(len(bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:39<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "iterations = 50\n",
    "eta = 0.1\n",
    "\n",
    "# dim -> hiperparametro que define la dimensioón de los vectores-palabra\n",
    "dim = 100\n",
    "m = 300\n",
    "N = len(idx)\n",
    "\n",
    "# Se usa para generar vectores one-shot\n",
    "matrix_I = np.identity(N)\n",
    "\n",
    "# Embebidding\n",
    "C = np.random.randn(dim,N) / np.sqrt(N)\n",
    "\n",
    "# Oculta\n",
    "W = np.random.randn(m,dim) / np.sqrt(dim)\n",
    "b = np.ones(m)\n",
    "\n",
    "# Salida\n",
    "U = np.random.randn(N,m) / np.sqrt(m)\n",
    "c = np.ones(N)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,iterations)):    \n",
    "    for bigram in bigrams:\n",
    "        \n",
    "        # FOWARD       \n",
    "        \n",
    "        # Capa embbeding\n",
    "        c_i = C.T[bigram[0]]\n",
    "        \n",
    "        # Capa oculta\n",
    "        h_i = np.tanh(np.dot(W,c_i) + b)\n",
    "        \n",
    "        # Pre-activacion\n",
    "        a = np.dot(U,h_i) + c\n",
    "        \n",
    "        # Salidas\n",
    "        tmp = np.exp(a - np.max(a))\n",
    "        # Aplicando softmax\n",
    "        f = tmp/tmp.sum(0)\n",
    "        \n",
    "        # BACKPROPAGATION para salida\n",
    "        d_out = f\n",
    "        k= bigram[1]\n",
    "        d_out[k] -= 1\n",
    "     \n",
    "        # Backpropagation para la capa oculta\n",
    "        dh = (1-h_i**2)*np.dot(U.T,d_out) \n",
    "        \n",
    "        # Backpropagation para la capa embedding\n",
    "        dc = np.dot(W.T,dh)\n",
    "        c -= eta*d_out\n",
    "\n",
    "        # Actualizacion de la capa de salida\n",
    "        U -= eta*np.outer(d_out,h_i)\n",
    "        \n",
    "        # Actualizacion de capa oculta\n",
    "        W -= eta*np.outer(dh,c_i)\n",
    "        b -=eta*dh\n",
    "        \n",
    "        # Actualizacion embedding\n",
    "        C -= eta*np.outer(dc,matrix_I[bigram[0]].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluación del modelo\n",
    "\n",
    "Entrenada la red, definimos una función forward para obtener las probabilidades a partir de la red ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    # Capa embbeding\n",
    "    c_i = C.T[x]\n",
    "    # Capa oculta\n",
    "    h_i = np.tanh(np.dot(W,c_i) + b)\n",
    "    # Pre-activacion\n",
    "    a = np.dot(U,h_i) + c\n",
    "    # Salidas\n",
    "    tmp = np.exp(a - np.max(a))\n",
    "    # Aplicando softmax\n",
    "    f = tmp/tmp.sum(0)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 0.4589028705666768),\n",
       " ('<oov>', 0.375203221035548),\n",
       " ('el', 0.019903881450556122),\n",
       " ('la', 0.018068401216105624),\n",
       " ('de', 0.017538984618931806),\n",
       " (')', 0.013839777020727712),\n",
       " ('(', 0.01192268955283356),\n",
       " ('en', 0.010403562515055994),\n",
       " ('y', 0.008298504917562764),\n",
       " ('que', 0.004777542066804815)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = []\n",
    "\n",
    "for word in idx.keys():\n",
    "    lista.append((word,forward(idx['recuerdo'])[idx[word]]))\n",
    "    #print(word,forward(idx['presidente'])[idx[word]])\n",
    "\n",
    "lista.sort(key=lambda x: x[1],reverse=True)\n",
    "\n",
    "lista[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD5CAYAAADY+KXfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjrUlEQVR4nO3de1xVZaL/8c8DGog6amZqXkB9eQG5KnijxLykeRhT02MNk5ml46RNpjHNL51Jp5xfpdOpjmnlmLfojJPmpeZMM2PZqN0EdItomploljmUQSCYgs/5Y+P2EgrIhg2L7/v12i/2Wnut50L5dfnsZz3LWGsRERFn8PN1A0RExHsU6iIiDqJQFxFxEIW6iIiDKNRFRBxEoS4i4iD1fFHpddddZ0NCQnxRtYjX5OTkEBAQQIMGDbxW5s6dO4mJieH06dN88cUXdOrUyWtlS+2Xnp7+jbW2xZWO8Umoh4SEkJaW5ouqRbxmwoQJJCYmMmbMmHKfU1RURL16l/9j16hRI/3ZkMsyxhwu6xgNv4iUyMrKIjQ0lEmTJtG9e3duueUWCgsLWbJkCXFxcURFRXH77bdTUFDABx98wMaNG0lOTiY6OpqDBw8yYMAATyB/8803nPvX6PLlyxkxYgQDBw5k0KBB5OfnM2jQIHr06EFERAQbNmwotS3h4eEA7Nmzh169ehEdHU1kZCQHDhyott+J1D4KdZELHDhwgKlTp7Jnzx6aNm3K2rVrGT16NKmpqezatYvQ0FCWLl1Kv379GDFiBPPnz8flcpU5TLJjxw7WrFnDv/71LwIDA1m3bh07duxg8+bNzJw5kyvd2f3iiy/y4IMP4nK5SEtLo23btt7utjiIT4ZfRGqqDh06EB0dDUDPnj3JysoiMzOT2bNnk5OTQ35+PkOHDq1wuUOGDOHaa68FwFrLo48+ypYtW/Dz8+PLL7/k+PHjtGrVqtRz+/bty7x58zh69CijR4+mc+fOV90/cT5dqYtcICAgwPPe39+foqIiJkyYwMKFC9m9ezePPfYYp06dKvXcevXqcfbsWYAfHdOwYUPP+5SUFLKzs0lPT8flctGyZcvLlgnws5/9jI0bN9KgQQOGDx/Ou+++W5kuisMp1EXKkJeXR+vWrTlz5gwpKSme/Y0bNyYvL8+zHRISQnp6OgBr1qy5bHm5ublcf/311K9fn82bN3P48JW/+/r888/p2LEjv/rVr7jtttvIyMioZI/EyRTqImV4/PHH6d27N/Hx8XTr1s2z/4477mD+/PnExMRw8OBBHn74YRYvXkxMTAzffPMNJ09CSAjccw+sXAnn/j5ISkoiLS2NiIgIVq5ceVGZpfnLX/5CeHg40dHRZGZmMn78+CrsrdR2xhdL78bGxlpN2xInS0mByZOhoOD8vqAgePllSEryXbukdjPGpFtrY690jK7URarArFkXBzq4t2fN8k17pO5QqItUgSNHKrZfxFsU6iJVoH37iu0X8RaFukgVmDfPPYZ+oaAg936RqqRQF6kCSUnuL0WDg8EY9099SSrVQXeUilSRpCSFuFQ/XamLiDiIQl1ExEEU6iIiDqJQFxFxEIW6iIiDKNRFRBxEoS4i4iAKdRERB1Goi4g4iEJdRMRBFOoiIg6iUBcRcRCFuoiIgyjURUQcRKEuIuIgCnUREQdRqIuIOIhCXUTEQRTqIiIOolAXEXGQSoe6MSbQGLPdGLPLGLPHGDPXGw0TEZGKq+eFMn4ABlpr840x9YFtxpi/WWs/8kLZIiJSAZUOdWutBfJLNuuXvGxlyxURkYrzypi6McbfGOMC/g3801r7cSnHTDbGpBlj0rKzs71RrYiIXMIroW6tLbbWRgNtgV7GmPBSjnnZWhtrrY1t0aKFN6oVEZFLeHX2i7U2B9gMDPNmuSIiUj7emP3SwhjTtOR9A2AIsK+y5YqISMV5Y/ZLa2CFMcYf918Sf7HWvuWFckVEpIK8MfslA4jxQltERKSSdEepiIiDKNRFRBxEoS4i4iAKdRERB1Goi4g4iEJdRMRBFOoiIg6iUBcRcRCFuoiIgyjURUQcRKEuIuIgCnUREQdRqIuIOIhCXUTEQRTqIiIOolAXEXEQhbqIiIMo1EVEHEShLiLiIAp1EREHUaiLiDiIQl1ExEEU6iIiDqJQFxFxEIW6iIiDKNRFRBxEoS4i4iAKdRERB1Goi4g4iEJdRMRBKh3qxph2xpjNxpi9xpg9xpgHvdEwERGpuHpeKKMImGmt3WGMaQykG2P+aa3d64WyRUSkAip9pW6tPWat3VHyPg/4BGhT2XJFRKTivDqmbowJAWKAj0v5bLIxJs0Yk5adne3NakVEpITXQt0Y0whYC0y31n5/6efW2pettbHW2tgWLVp4q1oREbmAV0LdGFMfd6CnWGvf8EaZIiJScd6Y/WKApcAn1tpnKt8kERG5Wt64Uo8H7gIGGmNcJa/hXihXREQqqNJTGq212wDjhbaIiEgl6Y5SEREHUaiLiDiIQl1ExEEU6iIiDqJQFxFxEIW6iIiDKNRFRBxEoS4i4iAKdRERB1Goi4g4iEJdRMRBFOoiIg6iUBcRcRCFuoiIgyjURUQcRKEuIuIgCnUREQdRqIuIOIhCXUTEQRTqIiIOolAXEXEQhbqIiIMo1EVEHEShLiLiIAp1EREHUaiLiDiIQl1ExEEU6iIiDqJQFxFxEK+EujHmFWPMv40xmd4oT0REro63rtSXA8O8VJaIiFwlr4S6tXYLcMIbZYmIyNWrtjF1Y8xkY0yaMSYtOzu7uqoVEalTqi3UrbUvW2tjrbWxLVq0qK5qRUTqFM1+ERFxEIW6iIiDeGtK4/8AHwJdjTFHjTH3eqNcERGpmHreKMRae6c3yhERkcrR8IuIiIMo1EVEHEShLiLiIAp1EREHUaiLiDiIQr0SXnzxRVauXOnrZoiIeHhlSmNdVFRUxJQpU3zdDBGRi9S6K/WsrCy6devGhAkT6NKlC0lJSWzatIn4+Hg6d+7M9u3bOXnyJBMnTqRXr17ExMSwYcMGAJYvX87IkSMZMmQIISEhLFy4kGeeeYaYmBj69OnDiRPuhSZdLhd9+vQhMjKSUaNG8d133wEwYMAApk+fTmxsLM899xxz5sxhwYIFACxZsoS4uDiioqK4/fbbKSgo8M0vSETqtFoX6gCfffYZM2fOZN++fezbt4/XXnuNbdu2sWDBAv7whz8wb948Bg4cyPbt29m8eTPJycmcPHkSgMzMTN544w1SU1OZNWsWQUFB7Ny5k759+3qGUsaPH89TTz1FRkYGERERzJ0711P36dOnSUtLY+bMmRe1afTo0aSmprJr1y5CQ0NZunRp9f1CRERK1Mrhlw4dOhAREQFA9+7dGTRoEMYYIiIiyMrK4ujRo2zcuNFzFX3q1CmOHDkCwM0330zjxo1p3LgxTZo04ac//SkAERERZGRkkJubS05ODgkJCQDcfffdjB071lP3uHHjSm1TZmYms2fPJicnh/z8fIYOHVpl/RcRuZxaGeoBAQGe935+fp5tPz8/ioqK8Pf3Z+3atXTt2vWi8z7++OMyzy1Lw4YNS90/YcIE1q9fT1RUFMuXL+e9996raLdERCqtVg6/lGXo0KH893//N9ZaAHbu3Fnuc5s0aUKzZs3YunUrAKtWrfJctV9JXl4erVu35syZM6SkpFxdw0VEKqlWXqmX5be//S3Tp08nMjKSs2fP0qFDB956661Sj12zBp58Eg4fhsaNoW9fWLFiBVOmTKGgoICOHTuybNmyMut8/PHH6d27Ny1atKB3797k5eV5u1siImUy565mq1NsbKxNS0ur9novlZICkyfDhRNVgoLg5ZchKcl37RIRKY0xJt1aG3ulYxw5/FJes2ZdHOjg3p41yzftERGprDod6iUTYsq9X0SkpqvTod6+fcX2i4jUdHU61OfNc4+hXygoyL1fRKQ2qtOhnpTk/lI0OBiMcf/Ul6QiUps5ckpjRSQlKcS9rVGjRuTn5/u6GSJ1Up2+UhcRcRqFulQZay3JycmEh4cTERHB6tWrATh27Bj9+/cnOjqaTp068fTTT1eqnkaNGnmjuSKOoFCXKvPGG2/gcrlo3rw5CxYsIDk5mWPHjvHaa68xdOhQ3n//fYKDgxkzZkyVteH06dOeFTq95dxSzCI1kUJdqsy2bdu48847McbQvHlzEhISSE1NJS4ujmXLlvHggw8yZcoUOnbs6JX68vPzGTRoED169KBLly7cdtttdO3alU8//RSAd955h5iYGCIiIpg4cSI//PDDZfe//fbbF63O+d5775GYmAjAyJEjGTFiBBs3bizXInAi1UmhLlfl5MmT/Md//AdRUVGEh4ezevVqfv/73xMXF0dBQQGTJ0/mwiUoVq1axV//+lceeOABAgMD2bJlC8XFxdx///2sXLmSN998k969exMTE8PgwYM5fvx4hdozcuRIbrzxRvbu3cv3339Ps2bN+PDDD9m1axcxMTGcOnWKCRMmsHr1anbv3k1RURGLFy/27P/Zz35GgwYNWL9+PTfffDM333wza9euJTk5maioKMaNG8ett94KuAN+xowZrFmzhtDQUB599FE+++wzr/5+Ra6WQl2uyttvv80NN9zArl27yMzMZNiwYUybNo3U1FSCgoIoLCykQYMGrF69GmstJ06coHHjxjz77LPcddddtGzZkoSEBMLCwtixYwc33ngjH330ETt37uSOO+6o8Dj7K6+8wsGDB7HW8sUXX3Dy5Eny8vI8T6Dav38/HTp0oEuXLoB7nfwtW7awf/9+WrZsyZYtW3j//fd5/fXX+frrrz3tBkhPT6ewsJCvv/4aAGMMAwYMYOXKlaSnp2OMoVu3bqxdu9aLv2GRq1PnpzTK1YmIiGDmzJk88sgjJCYmctNNN7F27VqefvppCgoKePfdd5k2bRqRkZEsWrSIvXuPAE9z++2jMOY+2rcPx9//JEVFRaxYsYKjR48ybtw4jh07xunTp+nQoUOp9Q4fPpw//elP3HDDDRftf/7552nQoAEnTpyguLiYvn37kpOTw6lTp8rsS05ODl999RVxcXHk5+eTnZ3N559/Tv369fnss89499136datG8eOHfOcU1hYyLp163jllVfIycnhueeeY8iQIZX6nYp4hbW22l89e/a04jv5+fl2+PDhNjIy0nbv3t3++c9/tsHBwTY7O9taa21qaqpNSEgos5xvv/3Wrlq1yvbv39/OnTvXXn/99fbIkSPWWmsfe+wx+9hjj1lrre3WLcEGBLxrwZa82tkGDXLs5MnL7NSpU6211iYkJNgNGzZYa63dvHlzueo/JzAw0MbHx9unn37aTps2zfbr18+OHDnSArZfv3720KFDtrCw0LZr184eOHDAWmvt3XffbZ999llbWFhomzZtan/xi19ctN9aaxs2bGiDg4PtmDFj7EMPPWTvvvtua621ycnJNiQkxE6dOtXu2LGj3O0UqSwgzZaRrxp+qYNKGzqpqK+++oqgoCB+/vOfk5yczI4dOwC47rrryM/PZ82aNZ5jDx2CH35YXbK1DWhCYWETLhytyM3NpU2bNoB7PfuKsNbSrFkz7rnnHjZu3MoHH3zI+vWF1KvXjV69kvH39ycwMJBly5YxduxYIiIi8PPzY8qUKQQGBvLHP/6RpUuXUb9+KCtW+DF//n/y3HOHAUhMTORvf/sbPXv29NQ3YMAAPvnkExYuXEhMTEyFf3ciVUnDL3VQaUMnFbV7926Sk5Px8/Ojfv36LF68mPXr1xMeHk6rVq2Ii4vzHOueZBIIxABngFcA+Pbb8+XNmTOHsWPH0qxZMwYOHMihQ4fK3Zbc3Fx69RpJq1Y3UVzcFWgK/IaiogE8//wgOnZcyQMPwKBBg0p9ClZAwET8/Bpy+vT/B9L48stEpk9/AYC33lrISy8tJCDg/F9Sw4cPL3fbRKpdWZfy5XkBw4D9wGfAb8o6XsMvvnfp0EmnTp3s8ePHrbXWbt26tULDH1fy6qvWGnNu2OUJC50txFu4wzZtOt8mJCTY1NRUa6212dnZNjg42FprbVFRke3bt69t27atjYiIsC+++KJ99VVrAwNvtfClDQ52l32ujqAge8HwzrlXsYX2FgouOv5SwcGlnXv+FRR0+XNFqhPVMfxijPEHXgBuBcKAO40xYZUtV6pOaUMnISEhpKenA3h1FsesWe5ohHTgz4AL+F8glZIZgqVaunQpgYGBPPjgg6SmpvLUU0u4775DnDr1v8ANHD7sfmpVSkrpDztx2wvcDjS46PhLlbV+vh6cIt6WlZVFeHh4lZTtjeGXXsBn1trPAYwxfwZuw/0nSmqgS4dORoxYzAsvFDJ8+L1cc81vGTx4gNfqOh+YW4FRwLm1jkfQowd89dXFx+fm5tKlSxdOnDjB6dOn2bdvH6+88gpZWVlYewvQClgCdPOE7eVDORx4xrN17vhLF3Br3979jNry9UOk+hQXF+Pv71+hc7zxRWkb4IsLto+W7LuIMWayMSbNGJOWnZ3thWrlag0dOpSMjAxcLhfTp6fy5JOxHD9+E/App0+n8d57C5g06T2v1HW5B440buz+Wa9ePc6ePQvA9u3bOXnyJC6Xi379+tGoUSNmzJhB69atsXYXcABYANzvKefIkYo91KS0cC5tXf3y9kOcLysri9DQUCZNmkT37t255ZZbKCwsxOVy0adPHyIjIxk1apRn+YgBAwbw0EMPERsbS2hoKKmpqYwePZrOnTsze/ZsT7lFRUUkJSURGhrKmDFjPPdUhISE8Mgjj9CjRw9ef/11/vGPf9C3b1969OgB0NEYc8XFjqpt9ou19mVrbay1NrZFixbVVa2Uoaqf03o+MPsD64FCGjTIIyjoTYCLhn2WLFlCUFAQQUFBJCYmEhQUxMmTJ/nggw+oV28EEAH8Ajg/X7x9+/KF8oXHX+rCdfXBvbb+hfTgFDlw4ABTp05lz549NG3alLVr1zJ+/HieeuopMjIyiIiIYO7cuZ7jr7nmGtLS0pgyZQq33XYbL7zwApmZmSxfvpxvS2YI7N+/n/vvv59PPvmEn/zkJyxatMhzfvPmzdmxYweDBw/miSeeYNOmTedmmBUAM67UVm+E+pdAuwu225bsk1qgqp/Tej4wewDjqFcvinbtbmXgQPfsmIcffpjFixcTEhLD22+fJDcXQkKgQYP7uPbaa1m0aBFFRUV07tyKBg224R6T/wQ4H7alPezkl7+s2FOtkpIgK8s9/r9qlR6cIhfr0KED0dHRAPTs2ZODBw+Sk5NDQkICcP4O5XNGjBgBuGeade/endatWxMQEEDHjh354gv3wEa7du2Ij48H4Oc//znbtm3znD9u3DgAPvroI/bu3Ut8fPy5+psDwVdqqzdCPRXobIzpYIy5BrgD2OiFcqUaVMdzWs8H5izOnPmU/fu3eW7X79atG488kkF29k5OnXoSaM/hw4X84hcnOXLkO5KTk4mLi2Pu3PtZsqQJ7dtbYNePwvZcHWfPun8uWnT1T7W6tKyrCfTi4uKKnyQ1VkBAgOe9v78/OTk55Trez8/vonP9/Pw8i8CZS/5JeOF2w4YNAffsxCFDhuByuXC5XAB7rLX3XqnuSoe6tbYImAb8Hfcl1F+stXsqW65Uj5rwnNbzQ0Duq3mIorDwVvLy4tixAw4fTuE//3Mp99wTRVFRd+bO3VCusK1sOGdlZdGtW7cfjXtebrXHS8dCxbmaNGlCs2bN2Lp1K+BesO7cVXt5HTlyhA8//BCA1157jRtvvPFHx/Tp04f333//wgXj/IwxXa5UrlduPrLW/i/ueWpSy5wLunOzSM6NUVf1cMOcOXM87y8e6pkF/ABcS0HBdDZsgIKCWcCtnDnzIDk50KlT1bbtQvv372fp0qXEx8czceJEnnnmGV566SXeeecdunTpwvjx41m8eDHTp08Hzo+FivOtWLGCKVOmUFBQQMeOHVm2bNkVj09JgY8+grg4aNMGWrfuygsvvMDEiRMJCwvjl7/85Y/OadGiBcuXL+fOO+88d/HQreT16WUrKmsie1W8dPORXOjHN/8cshBj/f3P3UDU0cI3ns9L7k+qcocOHbLt2rXzbL/zzjt2wIAB9qabbvLs27Rpkx01alRJP4JtVlZW9TROapXSbpC7mpva0NovUhv8eAgoBD+/5hQX7wT+gXt5geaeT6tzzvil455Nmza94vHnxkJFLlTVs8wupFAXnytt9sr9999H48bLgWXAxIuOr84545eOe8bGxpKVleUZ47yasVSpe6p6ltmFFOpSI1z6peYf/ziKhg3fxphUYKjnuOr+ErdrV/e4Z2hoKN999x0PPfQQSUnLCAsbizERrFnjR5MmU6qvQVIrVccss3O0SqPUSNdccw1hYTeTk9OUU6fct0k3bw7PPVe9c8br1avHq6++6tlOSYHnnx/EmTPu1R5PnoSpU6F+ffdsGZHSzJvnXnvowiGYqrpA0ZW61EirVp1l8+aPOHXq/JTcwkIfNqhEdY6NinOUNsRYVTe1GfcXqtUrNjbWpqWlVXu9Ujvs3buXqKhEiopGAX+86LPgYPfwjK/4+Z1bdfJixriHjkSqkjEm3Vobe6VjNPwiNU5YWBjFxZ+X+pmvV0u83IqOWvBLagoNv0iNVJ1fLFVETbgDV+RKFOpSI9XU8KzOsVGRq6HhF6mRfLV8QXkkJdWMdoiUxqdX6itXriQyMpKoqCjuuusu3nzzTXr37k1MTAyDBw/m+PHjAPzrX/8iOjqa6OhoYmJiyMvLw1pLcnIy4eHhREREsHq1+2n1x44do3///kRHRxMeHu5ZcEdqH2+slihS55S1jkBVvHr27GkzMzNt586dbXZ2trXW/SDkEydO2LNnz1prrV2yZImdMWOGtdbaxMREu23bNmuttXl5efbMmTN2zZo1dvDgwbaoqMh+/fXXtl27dvarr76yCxYssE888YS11v3w4u+//75iiyuIiNRQlGPtF58Nv7z77ruMHTuW6667DoBrr72W3bt3M27cOI4dO8bp06fp0KEDAPHx8cyYMYOkpCRGjx5N27Zt2bZtG3feeSf+/v60bNmShIQEUlNTiYuLY+LEiZw5c4aRI0d6FrYXEakLatQXpQ888ADTpk1j9+7dvPTSS5w6dQqA3/zmN/zpT3+isLCQ+Ph49u3bd9ky+vfvz5YtW2jTpg0TJkxg5cqV1dV8ERGf81moDxw4kNdff93zvL4TJ06Qm5tLmzbuZ1avWLHCc+zBgweJiIjgkUceIS4ujn379nHTTTexevVqiouLyc7OZsuWLfTq1YvDhw/TsmVLJk2axH333ae1rUWkTvHZ8Ev37t2ZNWsWCQkJ+Pv7ExMTw5w5cxg7dizNmjVj4MCBHDp0CIBnn32W9es3c/y4H2fOdCc19VbmzbuGyMgPiYqKwhjD008/TatWrVixYgXz58+nfv36NGrUSFfqIlKn1IplAlJSSl8MR/ODRaQuKc8yATVqTP1ytIiSiEj51IpQr84F5kVEarNaEeo1dR0QEZGaplaEek1dB0REpKapFaGuRZRERMqn1izopUWURETKViuu1EVEpHwU6iIiDqJQFxFxEIW6iIiDKNRFRBxEoS4i4iCVCnVjzFhjzB5jzFljzBUXmRERkapX2Sv1TGA0sMULbRGRapaVlUV4ePiP9v/ud79j06ZNlz1v/fr17N27t8L1vfjii1oOu4pV6uYja+0nAMYY77RGRGqE3//+91f8fP369SQmJhIWFlbuMouKipgyZUplmyZlqLYxdWPMZGNMmjEmLTs7u7qqFZEyFBcXM2nSJLp3784tt9xCYWEhEyZMYM2aNYD7cZJhYWFERkby8MMP88EHH7Bx40aSk5OJjo7m4MGDuFwu+vTpQ2RkJKNGjeK7774DYMCAAUyfPp3Y2Fiee+455syZw4IFCwBYsmQJcXFxREVFcfvtt1Nw6fraclXKDHVjzCZjTGYpr9sqUpG19mVrbay1NrZFixZX32IR8aoDBw4wdepU9uzZQ9OmTVm7dq3ns2+//ZZ169axZ88eMjIymD17Nv369WPEiBHMnz8fl8tFp06dGD9+PE899RQZGRlEREQwd+5cTxmnT58mLS2NmTNnXlTv6NGjSU1NZdeuXYSGhrJ06dJq67OTlTn8Yq0dXB0NERHf6NChA9HR0QD07NmTrKwsz2dNmjQhMDCQe++9l8TERBITE390fm5uLjk5OSQkJABw9913M3bsWM/n48aNK7XezMxMZs+eTU5ODvn5+QwdOtR7narDNKVRpI4LCAjwvPf396eoqMizXa9ePbZv386YMWN46623GDZsWIXLb9iwYan7J0yYwMKFC9m9ezePPfYYp06dqnjj5UcqO6VxlDHmKNAX+Ksx5u/eaZZI9cvJyWHx4sW+bkaNkp+fT25uLsOHD+e//uu/2LVrFwCNGzcmLy8PcF/NN2vWjK1btwKwatUqz1X7leTl5dG6dWvOnDlDSkpK1XWijqlUqFtr11lr21prA6y1La21+veT1AiNGjW64uc5OTksWrToon2/+tWvSp3eV5fl5eWRmJhIZGQkN954I8888wwAd9xxB/PnzyckJIY2bQ6SkbGCwYOTad8+EpfLxe9+97syy3788cfp3bs38fHxdOvWraq7UmcYa221VxobG2vT0tKqvV6pOxo1akR+fv5lP8/KyiIxMZHMzEwAjh8/zscff8yIESOqq4m1XkoKTJ588UPhg4L0AJuqZIxJt9Ze8UZPjamLo+Xn5zNo0CB69OhBREQEGzZsANzT9A4ePEh0dDTJyckUFhby6KOPArB8+XJGjx7NsGHD6Ny5M7/+9a992YUaa9asiwMd3NuzZvmmPeJWa558JHI1AgMDWbduHT/5yU/45ptv6NOnDyNGjODJJ58kMzMTl8sFcNGMDwCXy8XOnTsJCAiga9euPPDAA7Rr1676O1CDHTlSsf1SPRTq4mjWWh599FG2bNmCn58fX375JcePHy/zvEGDBtGkSRMAwsLCOHz4sEL9Eu3bw+HDpe8X39HwizhaSkoK2dnZpKen43K5aNmyZbmmzl1pmp+4zZvnHkO/UFCQe7/4jkJdHC03N5frr7+e+vXrs3nzZg6XXFpeOCVPrk5SkvtL0eBgMMb9U1+S+p6GX8TRkpKS+OlPf0pERASxsbGeqXPNmzenTZt4rrkmnDNnbqVNm6loXbqKS0pSiNc0mtIodZKm40ltpCmNIpeh6XjiVAp1qZM0HU+cSqEuddLlpt1pOp7Udgp1qZM0HU+cSqEudZKm44lTaUqj1FmajidOpCt1EREHUaiLiDiIQl1ExEEU6iIiDqJQFxFxEJ+s/WKMyQZKWYm5xrgO+MbXjagiTu4bOLt/6lvt5M2+BVtrW1zpAJ+Eek1njEkra9Gc2srJfQNn9099q52qu28afhERcRCFuoiIgyjUS/eyrxtQhZzcN3B2/9S32qla+6YxdRERB9GVuoiIgyjURUQcRKF+GcaY+caYfcaYDGPMOmNMU1+3yVuMMWONMXuMMWeNMY6YRmaMGWaM2W+M+cwY8xtft8ebjDGvGGP+bYzJ9HVbvM0Y084Ys9kYs7fk/8kHfd0mbzHGBBpjthtjdpX0bW511KtQv7x/AuHW2kjgU+D/+bg93pQJjAa2+Loh3mCM8QdeAG4FwoA7jTFhvm2VVy0Hhvm6EVWkCJhprQ0D+gBTHfTf7gdgoLU2CogGhhlj+lR1pQr1y7DW/sNaW1Sy+RHQ1pft8SZr7SfW2v2+bocX9QI+s9Z+bq09DfwZuM3HbfIaa+0W4ISv21EVrLXHrLU7St7nAZ8AbXzbKu+wbvklm/VLXlU+M0WhXj4Tgb/5uhFyWW2ALy7YPopDgqEuMcaEADHAxz5uitcYY/yNMS7g38A/rbVV3rc6/eQjY8wmoFUpH82y1m4oOWYW7n8iplRn2yqrPH0TqSmMMY2AtcB0a+33vm6Pt1hri4Hoku/k1hljwq21VfrdSJ0OdWvt4Ct9boyZACQCg2wtm9BfVt8c5kug3QXbbUv2SS1gjKmPO9BTrLVv+Lo9VcFam2OM2Yz7u5EqDXUNv1yGMWYY8GtghLW2wNftkStKBTobYzoYY64B7gA2+rhNUg7GGAMsBT6x1j7j6/Z4kzGmxblZc8aYBsAQYF9V16tQv7yFQGPgn8YYlzHmRV83yFuMMaOMMUeBvsBfjTF/93WbKqPkC+1pwN9xf9H2F2vtHt+2ynuMMf8DfAh0NcYcNcbc6+s2eVE8cBcwsOTPmcsYM9zXjfKS1sBmY0wG7guPf1pr36rqSrVMgIiIg+hKXUTEQRTqIiIOolAXEXEQhbqIiIMo1EVEHEShLiLiIAp1EREH+T9YqKJU8L9nigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = [w[0] for w in sorted(idx.items(), key=itemgetter(1))]\n",
    "plot_words(C.T[1:20],label[1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evalaur el modelo, necesitamos primero definir una función que nos de la probabilidad de las cadenas. Definimos esta función a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sent(sent):\n",
    "    #Obtenemos los simbolos\n",
    "    seq = sent.split()\n",
    "    #Obtenemos los bigramas de la cadena de evaluacion\n",
    "    bigrSeq = zip(seq,seq[1:])\n",
    "    \n",
    "    #Guardamos la probabilidad inicial dado el modelo\n",
    "    try:\n",
    "        p = forward(idx['<BOS>'])[idx[seq[0]]]\n",
    "    except: \n",
    "        p = forward(idx['<BOS>'])[idx['<oov>']]\n",
    "    #Multiplicamos por las probabilidades de los bigramas dado el modelo\n",
    "    for gram1, gram2 in bigrSeq:\n",
    "        #Obtiene las probabilidades de transición\n",
    "        #Dado el primer elemento\n",
    "        try:\n",
    "            prev_prob = forward(idx[gram1])\n",
    "        #En caso de que sea una OOV\n",
    "        except:\n",
    "            prev_prob = forward(idx['<oov>'])\n",
    "        #Obtiene la probabilidad de transitar a la siguiente palabra\n",
    "        try:\n",
    "            p *= prev_prob[idx[gram2]]\n",
    "        #En caso de que sea una OOV\n",
    "        except:\n",
    "            p *= prev_prob[idx['<oov>']]\n",
    "            \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con esto, podemos evaluar el modelo con entropía empírica (tomamos el promedio por cadena de ésta). Asimismo, con base en la entropía empírica podemos obtener la perplejidad como: \n",
    "$$Px(\\mu) = 2^{H(\\mu)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía promedio: 4.513982965024807\n",
      "Perplejidad total: 22.847793892443583\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del modelo\n",
    "H = 0.0\n",
    "for cad in corpus_eval:\n",
    "    #Probabilidad de la cadena\n",
    "    p_cad = prob_sent(' '.join(cad))\n",
    "    #Longitud de la cadena\n",
    "    M = len(cad)\n",
    "    #Obtenemos la entropía cruzada de la cadena\n",
    "    if p_cad == 0:\n",
    "        pass\n",
    "    else:\n",
    "        H -= (1./M)*(np.log(p_cad)/np.log(2))\n",
    "        \n",
    "H = H/len(corpus_eval)\n",
    "\n",
    "print('Entropía promedio: {}\\nPerplejidad total: {}'.format(H,2**H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calcular la probabilidad de 5 oraciones no vistas en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los ojos cerrados: 3.3808457467280676e-05\n",
      "los amigos: 0.003287193322150523\n",
      "la niña: 0.005108136196610822\n",
      "noticia negativa: 2.6219290726397295e-06\n",
      "el cielo estrellado: 7.81098116458294e-06\n"
     ]
    }
   ],
   "source": [
    "sents_not_seen = ['los ojos cerrados','los amigos','la niña','noticia negativa','el cielo estrellado']\n",
    "\n",
    "for sent in sents_not_seen:\n",
    "    print(\"{}: {}\".format(sent,prob_sent(sent)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Guardar los vectores de la capa de embedding asociados a las palabras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
