{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del Lenguaje Natural\n",
    "\n",
    "<img src=\"README.assets/nlp.png\" alt=\"pln\"/>\n",
    "\n",
    "## Generación de un modelo de lenguaje utilizando redes neuronales\n",
    "\n",
    "_Autor: Rodrigo Francisco Pablo_\n",
    "\n",
    "El modelo del lenguaje neuronal propuesto por Bengio (2003) es un modelo que estima probabilidades a partir de una red neuronal FeedForward. Como otros modelos, se puede entender como una tupla:\n",
    "\n",
    "$$\\mu = (\\Sigma, P)$$\n",
    "\n",
    "donde $\\Sigma$ es el vocabulario de palabras y $P = p(w_j|w_i)$ es la probabilidad de transición de $w_i$ a $w_j$. En este caso $P$ es una red FeedForward con una arquitectura constituida por:\n",
    "\n",
    "* Una capa de embedding.\n",
    "* Una capa oculta con activación $\\tanh$.\n",
    "* Una capa de salida con activación Softmax para obtener las probabilidades de transición.\n",
    "\n",
    "\n",
    "### Configuraciones previas\n",
    "\n",
    "Se realizan los *imports* necesarios para la creación del modelo. Para la creación del modelo se puede hacer uso de PyTorch o Tensorflow o cualquier otra librería que tenga redes neuronales pre-entrenadas, sin embargo, para este ejercicio se creará la red desde cero utilizando simplemente _numpy_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- encoding:utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos tres funciones:\n",
    "\n",
    "* Función para crear el vocabulario: asocia índices numéricos a palabras\n",
    "* Función para asociar a cada elemento, una palabra\n",
    "* Función para visualizar los embeddings por reducción de dimensionalidad con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que crea un vocabulario de palabras con un indice numero\n",
    "def vocab():\n",
    "    vocab = defaultdict()\n",
    "    vocab.default_factory = lambda: len (vocab)\n",
    "    return vocab\n",
    "\n",
    "# Funcion que pasa la cadena de simbolos a una secuencia con indices numericos\n",
    "def text2numba(corpus, vocab):\n",
    "    for doc in corpus:\n",
    "        yield [vocab[w] for w in doc]\n",
    "        \n",
    "#Función para visualizar los embeddings\n",
    "#Usa reducción de la dimensionalidad por PCA\n",
    "def plot_words(Z,ids):\n",
    "    Z = PCA(2).fit_transform(Z)\n",
    "    r=0\n",
    "    plt.scatter(Z[:,0],Z[:,1], marker='o', c='blue')\n",
    "    for label,x,y in zip(ids, Z[:,0], Z[:,1]):\n",
    "        plt.annotate(label, xy=(x,y), xytext=(-1,1), textcoords='offset points', ha='center', va='bottom')\n",
    "        r+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elección de un corpus\n",
    "\n",
    "Un **corpus** es una muestra bien organizada del nuestro lenguaje tomada de materiales escritos o hablados y que se encuentran agrupados bajo un críterio común. Para esta práctica se utilizará un corpus en *español*.\n",
    "\n",
    "Obtenemos las sentencias con las que vamos a trabajar. Tokenizamos por oraciones y cada oración, a su vez, es tokenizada por palabras para obtener los elementos que servirán para el modelo del lenguaje.\n",
    "\n",
    "Posteriormente, separamos los datos del corpus en el corpus de entrenamiento y el de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de oraciones en train: 88\n",
      "Número de oraciones en test: 39\n"
     ]
    }
   ],
   "source": [
    "# OPCION 1\n",
    "sents =  [word_tokenize(s) for s in sent_tokenize(open('corpus/funes_el_memorioso.txt','r').read())]\n",
    "\n",
    "#Split en corpus train y test\n",
    "corpus, corpus_eval = train_test_split(sents, test_size=0.3)\n",
    "\n",
    "print('Número de oraciones en train:',len(corpus))\n",
    "print('Número de oraciones en test:',len(corpus_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCION 2\n",
    "#import nltk\n",
    "#nltk.download('gutenberg')\n",
    "#sents = cess_esp.sents()\n",
    "#nltk.download('punkt')\n",
    "#sents = nltk.corpus.gutenberg.sents('shakespeare-macbeth.txt')\n",
    "\n",
    "# #Split en corpus train y test\n",
    "# corpus, corpus_eval = train_test_split(sents, test_size=0.3)\n",
    "\n",
    "# print('Número de oraciones en train:',len(corpus))\n",
    "# print('Número de oraciones en test:',len(corpus_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ver el número de tipos y tokens con el que cuenta el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tipos: 873 \n",
      "Número de tokens: 2244\n"
     ]
    }
   ],
   "source": [
    "#Frecuencia de los tipos\n",
    "freq_words= Counter( chain(*[' '.join(sent).lower().split() for sent in corpus]) )\n",
    "\n",
    "print('Número de tipos: {} \\nNúmero de tokens: {}'.format(len(freq_words), sum(freq_words.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sustitución de los hapax\n",
    "\n",
    "Ahora sustituiremos elementos del texto por el símbolo de fuera del vocabulario (Out Of Vocabulary) o $OOV$ esto nos permitirá manejar elementos que no se observen durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuevo corpus remplazando hápax por OOV\n",
    "corpus_hapax = []\n",
    "#Reemplazamos los hápax por OOV\n",
    "for sent in corpus:\n",
    "  sent_hapax =[]\n",
    "  for w in sent:\n",
    "    #Si es hápax\n",
    "    if freq_words[w.lower()] == 1:\n",
    "      #Se reemplaza por <oov>\n",
    "      sent_hapax.append('<oov>')\n",
    "    else:\n",
    "      #De otra forma se mantiene la palabra en mínuscula\n",
    "      sent_hapax.append(w.lower())\n",
    "  #Se agrupan las cadenas    \n",
    "  corpus_hapax.append(sent_hapax)\n",
    "    \n",
    "#print(corpus_hapax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Stemming\n",
    "\n",
    "Para esta tarea no realizará el proceso de steamming con la finalidad de simplificar la validación del modelo, ya que de otra manera se deberían reconstruir las cadenas a la hora de evaluar el modelo o a la hora de usarlo para alguna aplicación, por ejemplo, la generación de oraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Insertar símbolos de inicio y final de cadena\n",
    "\n",
    "Se indexa númericamente cada simbolo del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la funcion para crear un vocabulario\n",
    "idx = vocab() # Simplemente se renombra la funcion\n",
    "\n",
    "cads_idx = list(text2numba(corpus_hapax,idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, se colocarán etiquetas al inicio y al final de cada sentencia: BOS (Beginning of Sentence) y EOS (End of Sentence) respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "\n",
    "# A cada etiqueta se le asigna el indice número mayor \n",
    "# que el último indice asignado al vocabulario\n",
    "\n",
    "BOS_IDX = max(idx.values()) + 2\n",
    "EOS_IDX = max(idx.values()) + 1\n",
    "\n",
    "# Se agregan las etiquetas al vocabulario\n",
    "idx[EOS] = EOS_IDX\n",
    "idx[BOS] = BOS_IDX\n",
    "\n",
    "# Agregamos las etiquetas BOS al inicio y EOS al final de cada sentencia\n",
    "\n",
    "strings = [[BOS_IDX] + cad + [EOS_IDX] for cad in cads_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bigramas\n",
    "\n",
    "Antes de entrenar el modelo del lenguaje obtendremos los pares de entrenamiento que serán los pares obtenidos de bigramas, de tal forma que nuestro conjunto supervisado será:\n",
    "\n",
    "$$\\mathcal{S} = \\{(i,j) : (w_i, w_j) \\text{ es un bigrama}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de los bigramas construidos: 2332\n",
      "Bigramas: \n",
      "[(195, 0), (0, 0), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Creacion de bigramas\n",
    "bigrams = list(chain(*[zip(cad,cad[1:]) for cad in strings]))\n",
    "print(\"tamaño de los bigramas construidos: {}\".format(len(bigrams)))\n",
    "\n",
    "print(\"Bigramas: \")\n",
    "print(bigrams[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento de la red neuronal\n",
    "\n",
    "Como se mencionó al inicio, el modelo del lenguaje natural propuesto se base en la arquitectura porpuesta por Bengio(2003), la cual es una red neuronal de 3 capas, como se puede observar en la siguiente figura:\n",
    "\n",
    "<img src=\"README.assets/arquitectura.png\" alt=\"arquitectura\" width=\"200\"/>\n",
    "\n",
    "Para la fase de *FORWARD*:\n",
    "\n",
    "* Las entradas son vectores *one-hot* creados apartir de los indices de cada palabra en el vocabulario de entrenamiento. Por lo tanto si se tiene una palabra $w_3$, con indice 3, entonces el vector one-hot será:\n",
    "\n",
    "$$x(i) = \\begin{pmatrix}\n",
    "           0 \\\\\n",
    "           0 \\\\\n",
    "           1 \\\\\n",
    "           \\vdots \\\\\n",
    "           0\n",
    "         \\end{pmatrix}$$\n",
    "* Dicho vector *one-hot*, pasa a la capa de *embedding* _C_, tal que $C \\in \\mathbb{R}^{d\\times N}$, donde $N = |\\Sigma|$, es decir $N$ es el tamaño del vocabulario y $d$, es un hiperparámetro que representa la dimensiones de estas.\n",
    "\n",
    "* El resultado de la capa de embedding se pasa a la *capa oculta*, cuya función de activación _tanh_:\n",
    "\n",
    "$$h(i) := \\tanh(WC(i) + b)$$\n",
    "\n",
    "* En donde $W \\in \\mathbb{R}^{m\\times d}$ y $b$ es el bias, tal que $b \\in \\mathbb{R}^m$, con $m$ como otro hiperparámetro que representa las unidades ocultas.\n",
    "\n",
    "* Finalmente, la capa de salida esta dada por la pre-activación $a$, que se define de la siguiente forma:\n",
    "\n",
    "$$a(i):= Uh(i) + c$$\n",
    "\n",
    "* En donde $U \\in \\mathbb{R}^{N\\times m}$ y $c\\in \\mathbb{R}^N$\n",
    "* D esta forma, las palabras $w_k$ se indexan, mediante las entradas $a_k(i)$ de la pre-activación, por lo que la activación queda de la siguiente forma:\n",
    "\n",
    "$$p(w_j|w_i) = \\text{Softmax}[a_j(i)] := \\dfrac{e^{a_j(i)}}{\\sum_{k=1}^{K} e^{a_k(i)}}$$\n",
    "\n",
    "Por otra parte, se necesita una _función de riesgo_, dada por la entropía cruzada:\n",
    "\n",
    "$$R(\\theta) = - \\sum_i \\sum_k y_k \\ln p(w_k|w_i)$$\n",
    "\n",
    "* donde $y_k = 1$ si $k= j$, tal que $w_j$ es parte del bigrama $(w_i|w_j) y será 0 en cualquier otro caso.\n",
    "\n",
    "Fase de *BACKPROPAGATION*\n",
    "\n",
    "Para actualizar las matrices se utiliza el algoritmo de RETROPROPAGACIÓN (backpropagation), a continuación se enlistas las funciones de riesgo\n",
    "\n",
    "* Capa de salida}\n",
    "\n",
    "$$d_{out}(k) = p(w_k|w_i) - y_k$$\n",
    "\n",
    "* Capa oculta\n",
    "\n",
    "$$d_h(k) = [1-h(i)_k^2]\\sum_q U_{k,q} d_{out}(q)$$\n",
    "\n",
    "* Capa de embedding\n",
    "\n",
    "$$d_C(k) = \\sum_q W_{k,q}d_h(q)$$\n",
    "\n",
    "Fase *BACKWARDS*\n",
    "\n",
    "Para la actualización de los pesos se utiliza _gradiente descendiente_, de esta forma:\n",
    "\n",
    "* Para la capa de salida\n",
    "\n",
    "$$U_{l,k} \\leftarrow U_{l,k} - \\eta d_{out}(k)h(i)_l$$\n",
    "\n",
    "* Para la capa oculta\n",
    "\n",
    "$$W_{l,k} \\leftarrow W_{l,k} - \\eta d_h(k)C(i)_l$$\n",
    "\n",
    "* Para la capa de embedding\n",
    "\n",
    "$$C_{l,k} \\leftarrow C_{l,k} - \\eta d_C(k)\\times x(i)_l$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "iterations = 50\n",
    "eta = 0.1\n",
    "\n",
    "dim = 100\n",
    "m = 300\n",
    "N = len(idx)\n",
    "\n",
    "# Embebidding\n",
    "C = np.random.randn(dim,N) / np.sqrt(N)\n",
    "\n",
    "# Oculta\n",
    "W = np.random.randn(m,dim) / np.sqrt(dim)\n",
    "b = np.ones(m)\n",
    "\n",
    "# Salida\n",
    "U = np.random.randn(N,m) / np.sqrt(m)\n",
    "c = np.ones(N)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,iterations)):    \n",
    "    for bigram in bigrams:\n",
    "        \n",
    "        # FOWARD       \n",
    "        # Capa embbeding\n",
    "        c_i = C.T[bigram[0]]\n",
    "        \n",
    "        # Capa oculta\n",
    "        h_i = np.tanh(np.dot(W,c_i) + b)\n",
    "        \n",
    "        # Pre-activacion\n",
    "        a = np.dot(U,h_i) + c\n",
    "        \n",
    "        # Salidas\n",
    "        tmp = np.exp(a - np.max(a))\n",
    "        # Aplicando softmax\n",
    "        f = tmp/tmp.sum(0)\n",
    "        \n",
    "        # BACKPROPAGATION para salida\n",
    "        d_out = f\n",
    "        k= bigram[1]\n",
    "        d_out[k] -= 1\n",
    "     \n",
    "        # Backpropagation para la capa oculta\n",
    "        dh = (1-h_i**2)*np.dot(U.T,d_out) \n",
    "        \n",
    "        # Backpropagation para la capa embedding\n",
    "        dc = np.dot(W.T,dh)\n",
    "        c -= eta*d_out\n",
    "\n",
    "        # Actualizacion de la capa de salida\n",
    "        U -= eta*np.outer(d_out,h_i)\n",
    "        \n",
    "        # Actualizacion de capa oculta\n",
    "        W -= eta*np.outer(dh,c_i)\n",
    "        b -=eta*dh\n",
    "        \n",
    "        # Actualizacion embedding\n",
    "        C.T[bigram[0]] -= eta*dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la celda de arriba el entrenamiento duró _01:09_ segundos.\n",
    "\n",
    "La ejecución del algoritmo se realizó en una laptop Dell Inspiron 7559 con un procesador core i7 de sexta generación, como 8 núcleos;16 GB de ram y una GPU GeForce GTX 960M de 4GB.\n",
    "\n",
    "<img src=\"README.assets/monitor.png\" alt=\"monitor\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluación del modelo\n",
    "\n",
    "Entrenada la red, definimos una función forward para obtener las probabilidades a partir de la red ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    # Capa embbeding\n",
    "    c_i = C.T[x]\n",
    "    # Capa oculta\n",
    "    h_i = np.tanh(np.dot(W,c_i) + b)\n",
    "    # Pre-activacion\n",
    "    a = np.dot(U,h_i) + c\n",
    "    # Salidas\n",
    "    tmp = np.exp(a - np.max(a))\n",
    "    # Aplicando softmax\n",
    "    f = tmp/tmp.sum(0)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función _forward_ recibe como entrada el índice de una palabra $w_i$, y como resultado obtendremos las palabras $w_j$, subsecuentes, con sus respectivas probabilidades, a continuación se presenta el ejemplo de la palabra \"recuerdo\", con las 10 palabras y sus probabilidades ordenadas de mayor a menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 0.3022803630361966),\n",
       " ('(', 0.18773934724276287),\n",
       " ('de', 0.061414395761410376),\n",
       " ('el', 0.05688974739968049),\n",
       " ('<oov>', 0.05341479646823687),\n",
       " ('con', 0.041590779799881156),\n",
       " (')', 0.028328774827967383),\n",
       " (',', 0.019769271616732795),\n",
       " ('y', 0.01930154861850866),\n",
       " ('su', 0.018677854935803585)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = []\n",
    "\n",
    "for word in idx.keys():\n",
    "    lista.append((word,forward(idx['recuerdo'])[idx[word]]))\n",
    "    #print(word,forward(idx['presidente'])[idx[word]])\n",
    "\n",
    "lista.sort(key=lambda x: x[1],reverse=True)\n",
    "\n",
    "lista[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando _análisis de componentes principales(PCA)_ para reducir la dimensionalidad de los datos obtenidos se puede ver gráficamente la relación entre algunas palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = [w[0] for w in sorted(idx.items(), key=itemgetter(1))]\n",
    "plot_words(C.T[1:20],label[1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evalaur el modelo, necesitamos primero definir una función que nos de la probabilidad de las cadenas. Definimos esta función a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sent(sent):\n",
    "    #Obtenemos los simbolos\n",
    "    seq = sent.split()\n",
    "    #Obtenemos los bigramas de la cadena de evaluacion\n",
    "    bigrSeq = zip(seq,seq[1:])\n",
    "    \n",
    "    #Guardamos la probabilidad inicial dado el modelo\n",
    "    try:\n",
    "        p = forward(idx['<BOS>'])[idx[seq[0]]]\n",
    "    except: \n",
    "        p = forward(idx['<BOS>'])[idx['<oov>']]\n",
    "    #Multiplicamos por las probabilidades de los bigramas dado el modelo\n",
    "    for gram1, gram2 in bigrSeq:\n",
    "        #Obtiene las probabilidades de transición\n",
    "        #Dado el primer elemento\n",
    "        try:\n",
    "            prev_prob = forward(idx[gram1])\n",
    "        #En caso de que sea una OOV\n",
    "        except:\n",
    "            prev_prob = forward(idx['<oov>'])\n",
    "        #Obtiene la probabilidad de transitar a la siguiente palabra\n",
    "        try:\n",
    "            p *= prev_prob[idx[gram2]]\n",
    "        #En caso de que sea una OOV\n",
    "        except:\n",
    "            p *= prev_prob[idx['<oov>']]\n",
    "            \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para valuar el modelo se utilizará la entropía empírica (tomamos el promedio por cadena de ésta). \n",
    "\n",
    "La _entropía_ nos dice que tan incierto, es un sistema, por lo que un evento puede predecirse con mayor facilidad si presenta menor entropía, es decir, menos incertidumbre.\n",
    "\n",
    "Para efectos prácticamos y de comparación, tomese en cuenta que la entropía de lanzar una moneda es 1.\n",
    "\n",
    "Asimismo, con base en la entropía empírica podemos obtener la perplejidad como: \n",
    "\n",
    "$$Px(\\mu) = 2^{H_E(\\mu)}$$\n",
    "\n",
    "Esta última medida puede verse como el inverso multiplicativo de la probabilidad asignada al conjunto de pruebas por el modelo de lenguaje. Por lo tanto, tenemos que procurar que tenga un valor relativamente pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía promedio: 4.714470661614007\n",
      "Perplejidad total: 26.25409683934701\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del modelo\n",
    "H = 0.0\n",
    "for cad in corpus_eval:\n",
    "    #Probabilidad de la cadena\n",
    "    p_cad = prob_sent(' '.join(cad))\n",
    "    #Longitud de la cadena\n",
    "    M = len(cad)\n",
    "    #Obtenemos la entropía cruzada de la cadena\n",
    "    if p_cad == 0:\n",
    "        pass\n",
    "    else:\n",
    "        H -= (1./M)*(np.log(p_cad)/np.log(2))\n",
    "        \n",
    "H = H/len(corpus_eval)\n",
    "\n",
    "print('Entropía promedio: {}\\nPerplejidad total: {}'.format(H,2**H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calcular la probabilidad de 5 oraciones no vistas en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los ojos cerrados: 3.595871776051738e-05\n",
      "los amigos: 0.014433750015787911\n",
      "la niña: 0.014491615938017748\n",
      "noticia negativa: 0.01947038280006786\n",
      "el cielo estrellado: 3.89120871533712e-05\n"
     ]
    }
   ],
   "source": [
    "sents_not_seen = ['los ojos cerrados','los amigos','la niña','noticia negativa','el cielo estrellado']\n",
    "\n",
    "for sent in sents_not_seen:\n",
    "    print(\"{}: {}\".format(sent,prob_sent(sent)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Guardar los vectores de la capa de embedding asociados a las palabras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
